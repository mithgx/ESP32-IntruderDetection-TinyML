{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1eb61",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path to your dataset folder (change this to your dataset location)\n",
    "dataset_dir = r'X:\\mith\\COLLEGE\\PROJECTS\\embc\\tinyml'  # Example: 'dataset/'\n",
    "\n",
    "image_size = (96, 96)  # Images are already resized to 96x96\n",
    "\n",
    "# Function to load images from a folder and assign labels (e.g., 1 for face, 0 for no face)\n",
    "def load_images(dataset_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        img_path = os.path.join(dataset_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            images.append(cv2.resize(img, image_size))  # Ensure it's resized\n",
    "            labels.append(1)  # Assuming all images in the folder are faces (adjust if needed)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load the images and labels\n",
    "X, y = load_images(dataset_dir)\n",
    "\n",
    "# Normalize the images (scale pixel values to [0, 1])\n",
    "X = X / 255.0\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shape of the dataset\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(96, 96, 3)),  # Input size: 96x96x3 (RGB)\n",
    "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Output 1: Face (1) or No Face (0)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model\n",
    "model.save(r'C:\\Users\\mithi\\Downloads\\face\\templates\\face_detection_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabc2109-ada7-474b-bcc1-ccfd1c0eef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mithi\\AppData\\Local\\Temp\\tmpwmdgqu8n\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mithi\\AppData\\Local\\Temp\\tmpwmdgqu8n\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\mithi\\AppData\\Local\\Temp\\tmpwmdgqu8n'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='keras_tensor_30')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2934127472528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2934127471568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2933805567440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2933805563984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2933805564752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2933805565712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2933805565328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2933805565136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2933805566096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2933805567824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Model saved in: C:\\Users\\mithi\\Downloads\\face\\templates\\face_detection_model2.tflite\n"
     ]
    }
   ],
   "source": [
    "custom_directory = r\"C:\\Users\\mithi\\Downloads\\face\\templates\"  # Change this to your desired directory\n",
    "import tensorflow as tf\n",
    "\n",
    "if not os.path.exists(custom_directory):\n",
    "    os.makedirs(custom_directory)\n",
    "\n",
    "# Converting to TensorFlow Lite format\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Apply optimization to reduce size\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "tflite_model_path = os.path.join(custom_directory, \"face_detection_model2.tflite\")\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model saved in: {tflite_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d1d0f-7eaa-4c8b-badf-8818827977e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
